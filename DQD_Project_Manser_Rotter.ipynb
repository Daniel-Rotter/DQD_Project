{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc31960a",
   "metadata": {},
   "source": [
    "# Image Inpainting using CNNs\n",
    "By Daniel Manser and Daniel Rotter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c848b9ab",
   "metadata": {},
   "source": [
    "## Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c4aef",
   "metadata": {},
   "source": [
    "## Problemstellung (Rotter)\n",
    "\n",
    "Das Ziel von Image Inpainting ist es, fehlende oder beschädigte Informationen aus Bild- oder Videomaterial zu rekonstruieren. Die Technik des Image Inpainting hat eine Vielzahl von Use-Cases ermöglicht. Image Inpainting wird aber nicht ausschließlich für fehlende Pixel verwendet, sondern auch für Aufgaben wie zum Beispiel dem Schärfen von Bildern, dem Entfernen von Rauschen oder dem Entfernen von Artefakten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3999295",
   "metadata": {},
   "source": [
    "## Herausforderungen (Rotter)\n",
    "\n",
    "Die große Herausforderung ist es, die fehlenden oder beschädigten Teile von Bildern oder Videos sowohl visuell, als auch semantisch passend zu füllen. \n",
    "\n",
    "Convolutional Neural Networks (CNN) sind speziell für Rasterförmige Datensätze geeignet. Bilder können dabei als 2D Raster von Pixeln mit unterschiedlichen Farb- und Helligkeitswerten angesehen werden. Die Herausforderung bei der Umsetzung von Image Inpainting mit CNNs ist es, das Netzwerk so zu trainieren, dass es sinnvolle Vorhersagen für die fehlenden Pixel trifft.\n",
    "\n",
    "CNN-basierte Methoden können zu Grenzartefakten, verzerrten und unscharfen Flecken am rekonstruierten Bild führen. Diese Arten von Artefakten können durch Post-processing Methoden reduziert werden, die aber vergleichsweise viel Rechenleistung erfordern und nicht so allgemein anwendbar sind. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c179bf",
   "metadata": {},
   "source": [
    "## Architektur (Manser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38206729",
   "metadata": {},
   "source": [
    "Unsere Architektur basiert auf einem konvolutionalen Autoencoder, einer speziellen Form eines Encoder-Decoder-Modells, das in der Bildverarbeitung insbesondere für Aufgaben wie Image Inpainting eingesetzt wird. Ziel ist es, fehlende Bildbereiche auf Basis des umgebenden Kontexts möglichst realistisch zu rekonstruieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d9496",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3891e",
   "metadata": {},
   "source": [
    "Der Encoder besteht aus einer Sequenz von Convolutional Layers (z. B. mit 3×3-Filtern), gefolgt von nichtlinearen Aktivierungsfunktionen (typischerweise ReLU - Rectified Linear Unit) und Downsampling mittels MaxPooling.\n",
    "Diese Kombination reduziert die räumliche Auflösung des Bildes und extrahiert zunehmend abstrakte Merkmale. Dadurch wird eine komprimierte, semantisch bedeutungsvolle Darstellung erzeugt. [Rosebrock (2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1249bc",
   "metadata": {},
   "source": [
    "#### Pooling\n",
    "\n",
    "**Pooling** reduziert die räumliche Auflösung einer Merkmalskarte, indem in kleinen Bereichen (z.B. 2x2 Pixel) jeweils ein einzelner Wert berechnet wird - typischerweise das Maximum (MaxPooling) oder der Mittelwert (AveragePooling). Dadurch werden Informationen verdichtet und die Modellkomplexität verringert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6784c06",
   "metadata": {},
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7cf3d",
   "metadata": {},
   "source": [
    "Im Zentrum der Architektur befindet sich der sogenannte **Bottleneck**, eine stark verdichtete Repräsentation des ursprünglichen Bildinhalts. Sie enthält alle wesentlichen Informationen, um das Bild – inklusive der maskierten Bereiche – wiederherzustellen.\n",
    "Der Bottleneck spielt eine zentrale Rolle bei der semantischen Vervollständigung des Bildes und ist charakteristisch für alle Autoencoder-basierten Ansätze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c1420",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2560b9a",
   "metadata": {},
   "source": [
    "Der **Decoder** kehrt den Prozess des Encoders um: Mithilfe von **Transposed Convolutions** oder **Upsampling + Convolution** wird das Bild schrittweise wieder auf seine ursprüngliche Größe gebracht. Dabei werden auch die **fehlenden Bildbereiche** rekonstruiert. Der Artikel von Weights & Biases (2022) betont, dass CNNs besonders gut darin sind, sowohl **lokale Strukturen** als auch den **globalen Kontext** wiederherzustellen - ein zentrales Kriterium für glaubwürdiges Image Inpainting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68f229",
   "metadata": {},
   "source": [
    "#### Abbildung einer Autoencoder-Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc45dc1",
   "metadata": {},
   "source": [
    "![Abbildung einer Autoencoder-Architektur](./images/image_autoencoder.png)\n",
    "\n",
    "**Abbildung:** Darstellung eines symmetrischen Autoencoders mit Encoder, Bottleneck („Code“) und Decoder. Diese Architekturform bildet die Grundlage vieler Inpainting-Modelle.  \n",
    "Quelle: Weights & Biases (2022) – [Introduction to Image Inpainting with Deep Learning](https://wandb.ai/wandb_fc/articles/reports/Introduction-to-image-inpainting-with-deep-learning--Vmlldzo1NDI3MjA5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fe361",
   "metadata": {},
   "source": [
    "## Quellen  \n",
    "- Waghela, V. (2022). Image Inpainting using CNN. Kaggle.\n",
    "https://www.kaggle.com/code/vidhikishorwaghela/image-inpainting-using-cnn\n",
    "\n",
    "- Weights & Biases. (2022). Introduction to Image Inpainting with Deep Learning.\n",
    "https://wandb.ai/wandb_fc/articles/reports/Introduction-to-image-inpainting-with-deep-learning--Vmlldzo1NDI3MjA5\n",
    "\n",
    "- Rosebrock, A. (2020). Autoencoders with Keras, TensorFlow, and Deep Learning.\n",
    "https://pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9e6a2",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "- Kurzbeschreibung Datensatz\n",
    "- Kurzbeschr. der Methode\n",
    "- Verwendete Software\n",
    "- Wichtigste Erkenntnisse und Resultate\n",
    "- Zentrale Herausforderungen"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
